---
title: "hw_2"
author: "Bibaeva Masha"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(irr)
```
### 1.1

Скачайте датасет hw1_1_zilo_class.csv (см. описание выше). Получите тиббл содержащий два столбца: stimulus_source и количество уникальных слов в датасете (n).  

```{r}
zilo <- as_tibble(read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/mbibaeva/hw2_agreement/hw2_1_zilo_class.csv'))

zilo %>%
  distinct(stimulus_source, translation_ru) %>% 
  count(stimulus_source)
```

### 1.2

Преобразуйте датасет hw1_1_zilo_class.csv. Посчитайте процент полного согласия всех спикеров.

```{r}
zilo %>%
  select(s_id, stimulus, translation_ru, stimulus_source, class) %>% 
  spread(key = s_id, value = class) ->
  zilo_short
#head(zilo_short)

agree(zilo_short[,-c(1:3)])
```

### 1.3

Из преобразованным датасета hw1_1_zilo_class.csv выберите спикеров с номером 7 и 11 и посчитайте для них каппу Коэна.

```{r}
zilo_711 <- zilo_short[,c(7, 11)]
kappa2(zilo_711)
```

### 1.4

Посчитайте каппу Фляйса для всех спикеров преобразованного датасета hw1_1_zilo_class.csv.

```{r}
kappam.fleiss(zilo_short[,-c(1:3)])
```

### 1.5

Представим, что Вы пишите статью, напишите короткий абзац, который бы обобщал результаты, полученные в предыдущих заданиях.

С помощью метрик согласия было проанализировано восприятие носителями андийского языка села Зило заиствованной и исконной лексики в плане отнесения её к тому или иному классу. Процент согласия оказался равен 73, каппа Коэна для двух информантов показала разницу в 0.771, а каппа Фляйса - 0.849. Результаты получились достаточно близкими и демонстрируют, что разница в суждениях довольно мала. В целом все метрики показали, что носители в основном согласны между собой насчёт того, к какому классу относить слова.

### 2.1

Скачайте датасет hw1_2_verbs.csv (см. описание выше). Посчитайте количество участников в датасете (в ответ выведите тибл с переменной n).

```{r}
verbs <- as_tibble(read.csv('https://raw.githubusercontent.com/agricolamz/2018_data_analysis_for_linguists/master/data/students/mbibaeva/hw2_agreement/hw2_2_verbs.csv'))
verbs %>%
  distinct(SubjectCode) %>%
  summarize(n = n())
```

### 2.2

Посчитайте среднюю оценку глаголов разного типа для каждого пола в датасете (в ответ выведите тибл с переменными WordType, Gender и mean).

```{r}
verbs %>%
  group_by(WordType,Gender) %>%
  summarize(mean = mean(GivenScore))
```

### 2.3

Преобразуйте датасет в короткий формат и удалите строки, в которых есть пропущенные значения (у меня вышел тибл 59 x 124). Посчитайте процент полного согласия.

```{r}
verbs %>% 
  select(SubjectCode, Stimulus, WordType, Prefix, GivenScore) %>% 
  spread(key = SubjectCode, value = GivenScore) %>%
  drop_na() ->
  verbs_short
agree(verbs_short[,-c(1:3)])
```

### 2.4

Посчитайте каппу Фляйса для преобразованного датасета.

```{r}
kappam.fleiss(verbs_short[,-c(1:3)])
```

### 2.5

Посчитайте ICC для преобразованного датасета.

```{r}
icc(verbs_short[,-c(1:3)], model = "twoway", type = "agreement")
```

### 2.6

Создайте тибл, содержащий минимальное (min) и максимальное (max) значение попарной корреляции Кендала ответов всех участников эксперимента со словами (т. е. корреляция ответов АА и AB, AA и AC и т. д.). В преобразовании матрицы, пораждаемой функцией cor() мне очень помогла функция as.table().

```{r}
verbs_correlation <- cor(verbs_short[,-c(1:3)], method = "kendall")
extremums <- tibble(first=rownames(verbs_correlation)[row(verbs_correlation)[upper.tri(verbs_correlation)]], 
              second=colnames(verbs_correlation)[col(verbs_correlation)[upper.tri(verbs_correlation)]],
              correlation = verbs_correlation[upper.tri(verbs_correlation)])
tibble(min=min(extremums$correlation),max=max(extremums$correlation))
```

